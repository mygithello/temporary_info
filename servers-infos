ps -ef | grep aa.jar|awk '{print $2}' | xargs kill -9

docker run --net staticnet --ip 172.172.0.6  --privileged=true --name oracle-sqlplus  mydockerhello/centos7-ssh:1.0.4 /sbin/init


//如何创建 确定 hive 内部表 和外部表 
当重新创建 已经drop过的外部表时，创建完毕后，发现原来的数据仍在表里


LOAD DATA [LOCAL] INPATH 'filepath' [OVERWRITE] INTO TABLE tablename [PARTITION (partcol1=val1, partcol2=val2 ...)]
//insert 哪怕一条，也会创建一个mapreduce 任务，我们选择Load Data 方式

Error running 'ServiceStarter': Command line is too long. Shorten command line for ServiceStarter or also for Application default configuration.

解法:
修改项目下 .idea\workspace.xml，找到标签 <component name="PropertiesComponent"> ， 在标签里加一行  <property name="dynamic.classpath" value="true" />


hadoop fs -ls /user/hive/warehouse
./beeline -u jdbc:hive2://localhost:10000 -n hadoop

drop database if exists test;

RITM0626862 新电脑  ticket

sqoop 增量导入
https://blog.csdn.net/wiborgite/article/details/80786002
发布包
https://blog.csdn.net/anmaiwo1812/article/details/102117602?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.nonecase&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.nonecase

./kafka-topics.sh -create -zookeeper localhost:2181 -replication-factor 2 -partitions 4 -topic test-name


docker run --net staticnet --ip 172.172.0.6 --add-host airflow-worker:172.172.0.7  --privileged=true --name airflow-scheduler --hostname airflow-scheduler -d -P -p 5672:5672 -p 8082:8080  -p 15672:15672 -p 25672:25672 -p 4369:4369 mydockerhello/airflow-scheduler:1.0.1 /sbin/init


export PYTHONIOENCODING=utf-8

authenticate = True auth_backend = airflow.contrib.auth.backends.password_auth filter_by_owner = True


手把手教你搭建大数据分析平台——Cloudera Manager常见问题解决

/ # while true; do wget -q -O- http://172.17.0.5:8080; done


k8s
https://blog.csdn.net/qq_28513801/article/details/98076359
nginx设置：
192.168.80.3:8083/servers/airflow-scheduler/15672 -----172.172.0.8:80/servers/airflow-scheduler/15672   --> 172.172.0.7:15672


https://www.cnblogs.com/brock0624/p/9788710.html


https://blog.csdn.net/Linjingke32/article/details/80993870

朗读工具
https://zhuanlan.zhihu.com/p/91092428

常用软件
https://blog.csdn.net/f8qg7f9yd02pe/article/details/83005700


单个含有main方法的.class 文件如何手动打成jar包：

1.javac FormatUtf8.java 编译.class文件（个别编译报错的部分可以注释掉）
2.将.class 文件package目录下（在当前目录下新建.class中package 对应的同等目录结构）


./kafka-console-consumer.sh --zookeeper localhost:2181 --topic test-metrics2 --from-beginning

3.在当前目录新建manifest.mf 文件，
内容：
Manifest-Version: 1.0
Main-Class: convertAscIIToUtf8.FormatUtf8
convertAscIIToUtf8.FormatUtf8：为包路径.类名
4.当前目录运行jar cfm test.jar manifest.mf convertAscIIToUtf8/
5.查看当前目录打成名为test.jar，测试jar包是否正常。




https://www.youneed.win/free-ssr


tag="1.0.4"

docker run --net staticip --ip 172.172.0.2 --add-host dn1:172.172.0.3 --add-host dn2:172.172.0.4 --add-host n-rabbitmq:172.172.0.5 --privileged=true --name nna --hostname nna -d -P -p 50070:50070 -p 8088:8088 mydockerhello/nna:${tag} /sbin/init
wait
docker run --net staticip --ip 172.172.0.3 --add-host nna:172.172.0.2 --add-host dn2:172.172.0.4 --add-host n-rabbitmq:172.172.0.5 --privileged=true --name dn1 --hostname dn1 -d -P mydockerhello/dn1:${tag} /sbin/init
wait
docker run --net staticip --ip 172.172.0.4 --add-host nna:172.172.0.2 --add-host dn1:172.172.0.3 --add-host n-rabbitmq:172.172.0.5 --privileged=true --name dn2 --hostname dn2 -d -P mydockerhello/dn2:${tag} /sbin/init

https://blog.51cto.com/10647376/2322552?source=dra


create database monitor_strategy owner yacus;
grant all privileges on database collect_strategy to yacus;

drools:demo
https://blog.csdn.net/tanglei6636/article/details/94845270

https://zhang.ge/5126.html

Jyc25134526s

https://console.cloud.tencent.com/tke2/registry/user/self?rid=1
docker pull jaspeen/oracle-11g



> use xxx? ? ? ? ? ? ? ? ?使用某个数据库
>?show measurements? ? 显示表，默认有name,?_internal(用于内部实时监控数据)
> precision rfc3339? ? ? ? ? 将时间戳从19位数字转成类似 2018-11-19T21:10:52.793Z
> select * from xxx?ORDER BY time DESC LIMIT 3? ? 显示xxx表最新的三条数据.select和mysql操作一致
> delete from "xxx" where time < '2019-01-01'? 删除满足条件的字段
> show series from "xxx"? ? 显示series
>show? tag keys from "xxxxx"? ?显示某表的tag


SHOW FIELD KEYS --查看当前数据库所有表的字段
SHOW series from pay --查看key数据
SHOW TAG KEYS FROM "pay" --查看key中tag key值
SHOW TAG VALUES FROM "pay" WITH KEY = "merId" --查看key中tag 指定key值对应的值
SHOW TAG VALUES FROM cpu WITH KEY IN ("region", "host") WHERE service = 'redis'
DROP SERIES FROM <measurement_name[,measurement_name]> WHERE <tag_key>='<tag_value>' --删除key
SHOW CONTINUOUS QUERIES   --查看连续执行命令
SHOW QUERIES  --查看最后执行命令
KILL QUERY <qid> --结束命令
SHOW RETENTION POLICIES ON mydb  --查看保留数据
查询数据
SELECT * FROM /.*/ LIMIT 1  --查询当前数据库下所有表的第一行记录
select * from pay  order by time desc limit 2
select * from  db_name."POLICIES name".measurement_name --指定查询数据库下数据保留中的表数据 POLICIES name数据保留
删除数据
delete from "query" --删除表所有数据，则表就不存在了
drop MEASUREMENT "query"   --删除表（注意会把数据保留删除使用delete不会）
DELETE FROM cpu
DELETE FROM cpu WHERE time < '2000-01-01T00:00:00Z'
DELETE WHERE time < '2000-01-01T00:00:00Z'
DROP DATABASE “testDB” --删除数据库
DROP RETENTION POLICY "dbbak" ON mydb --删除保留数据为dbbak数据
DROP SERIES from pay where tag_key='' --删除key中的tag

SHOW SHARDS  --查看数据存储文件
DROP SHARD 1
SHOW SHARD GROUPS
SHOW SUBSCRIPTIONS


在influxdb中没有专门用来创建measurement的命令，在执行向某个measurement新增记录的时候，如果不存在measurement，则会新创建一个

 ll xsb90.txt |awk '{print  $6 "-" $7 "-" $8 }'
